{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQ9inwswBLfyDXuP/GgqzO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cmyXjYNCMSyu","executionInfo":{"status":"ok","timestamp":1767883530589,"user_tz":-360,"elapsed":57,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}},"outputId":"3c666a76-2417-40bb-f4e9-38dba803b666"},"outputs":[{"output_type":"stream","name":"stdout","text":["﻿I HAD always thought Jack Gisburn rather a cheap genius-- though a good fellow enough--so it was no\n"]}],"source":["with open('/content/The_Verdict.txt','r', encoding = 'utf-8') as f:\n","  text = f.read()\n","\n","\n","print(text[:100])"]},{"cell_type":"code","source":["!pip3 install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RLYx4I6Q6ws","executionInfo":{"status":"ok","timestamp":1767883538220,"user_tz":-360,"elapsed":5741,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}},"outputId":"86c57036-15c1-48af-c9a0-6bd5e90b2d27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n"]}]},{"cell_type":"code","source":["import tiktoken\n","import importlib\n","tokenizer = tiktoken.get_encoding(\"gpt2\")"],"metadata":{"id":"lqLehbhVREAx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_text = tokenizer.encode(text)\n","encoded_text[:100]\n"],"metadata":{"id":"L63j7ESuR6Ps"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context_size = 4 #how many previous tokens the model can see when predicting the next one. also called block_size, sequence_length,max_sq_len,context_length\n","\n","#\"I\" → \"love\"\n","#\"I love\" → \"deep\"\n","#\"I love deep\" → \"learning\"\n","\n","''' x = [171, 119, 123, 40]\n","y = [119, 123, 40, 367] '''\n","\n","''' input 171 → output 119 ✔\n","\n","input [171,119] → output 123 ✔\n","\n","input [171,119,123] → output 40 ✔\n","\n","input [171,119,123,40] → output 367 ✔ '''\n","\n","\n","x = encoded_text[:context_size]\n","y = encoded_text[1:context_size+1]\n","\n","print(x)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZYuN2WKXUZxC","executionInfo":{"status":"ok","timestamp":1767883560613,"user_tz":-360,"elapsed":29,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}},"outputId":"94f532e9-f238-439b-b011-21101dc177a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[171, 119, 123, 40]\n","[119, 123, 40, 367]\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def create_tf_dataset(ids, block_size):\n","    ids = tf.constant(ids, dtype=tf.int32) #Converts your list of token IDs into a\n","                                                                        #TensorFlow tensor. ids = [171, 119, 123, 40, 367] becomes tf.Tensor([171,119,123,40,367], shape=(5,), dtype=int32)\n","\n","    dataset = tf.data.Dataset.from_tensor_slices(ids) #Creates a tf.data.Dataset where each element is one token ID.\n","    dataset = dataset.window(block_size + 1, shift=1, drop_remainder=True) #Creates sliding windows over the dataset.\n","    '''block_size + 1 → Each window has C input tokens + 1 extra token for target.\n","      shift=1 → Window moves one token at a time, giving overlapping windows.\n","      drop_remainder=True → Discards incomplete windows at the end. '''\n","\n","\n","    dataset = dataset.flat_map(lambda x: x.batch(block_size + 1)) #Each element from window() is a dataset itself, not a tensor. flat_map(...batch(...))\n","                                                                                                                      # converts each window dataset into a proper tensor of shape (block_size+1,).\n","                                                                                                                      #Now each element is a tensor of token IDs.\n","                                                                                                                      #tf.Tensor([171, 119, 123, 40, 367], shape=(5,), dtype=int32)\n","\n","    dataset = dataset.map(lambda x: (x[:-1], x[1:]))  #Now we create input–target pairs.\n","                                                                                            #x[:-1] → all tokens except the last → inputs(in current window)\n","                                                                                            #x[1:] → all tokens except the first → targets (shifted by 1)(in current window)\n","    return dataset\n","\n","    #In a long text with 1M tokens, it would produce many overlapping input-target pairs, one per shift of 1.\n"],"metadata":{"id":"z5Gl9IATEdCS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["block_size = 4\n","dataset = create_tf_dataset(encoded_text, block_size)\n","p = 3\n","for x, y in dataset:\n","    print(\"Input:\", x.numpy(), \"Target:\", y.numpy())\n","    p-=1\n","    if p == 0:\n","        break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yfKOJSAPcJt9","executionInfo":{"status":"ok","timestamp":1767890144887,"user_tz":-360,"elapsed":50,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}},"outputId":"f5dc05fd-e62d-4ea3-d1c6-7987def4c799"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: [171 119 123  40] Target: [119 123  40 367]\n","Input: [119 123  40 367] Target: [ 123   40  367 2885]\n","Input: [ 123   40  367 2885] Target: [  40  367 2885 1464]\n"]}]},{"cell_type":"markdown","source":["#What happens if there are millions (or billions) of IDs?\n","Short answer\n","\n","✔ Conceptually: Yes, it defines all possible sliding windows\n","\n","✔ Practically: No, they are NOT all created in memory\n","\n","\n","#✔️ What actually happens (step-by-step)\n","\n","Windows are NOT generated beforehand\n","\n","No giant list of windows\n","\n","No massive memory usage\n","\n","tf.data.Dataset defines a pipeline\n","\n","A recipe for how to create windows\n","\n","Not the windows themselves\n","\n","During training, for each step:\n","\n","TensorFlow pulls the next slice of token IDs\n","\n","Forms a window on the fly\n","\n","Creates the (input, target) pair\n","\n","Batches it\n","\n","Sends it to the model\n","\n","Only the input part goes into the embedding layer\n","\n","target is used only for loss calculation"],"metadata":{"id":"A04d2gJQdZS8"}},{"cell_type":"markdown","source":["#What is a batch?\n","\n","A batch is a group of multiple training examples processed together in one forward/backward pass of the model.\n","\n","Instead of:\n","\n","feeding one (input, target) pair at a time\n","\n","We feed:\n","\n","many (input, target) pairs at once\n","\n","Why batching exists (very important)\n","\n","\n","❌ Without batching\n","\n","Very slow\n","\n","GPU mostly idle\n","\n","High variance gradients\n","\n","✅ With batching\n","\n","GPU computes in parallel\n","\n","Faster training\n","\n","More stable gradients"],"metadata":{"id":"24-D50k6fqP8"}},{"cell_type":"markdown","source":["#Important Concepts\n","\n","The model NEVER keeps track of input–target pairs.\n","The PAIRING exists only in the loss function, not inside the model.\n","\n","Target IDs play the same role as labels in supervised learning.\n","\n","**LLM training = supervised learning (but auto-generated)**\n","\n","\n","\n","#Final one-sentence rule (memorize this)\n","\n","Input–target pairing exists only in the loss; the model learns causality through masked attention and gradient feedback."],"metadata":{"id":"-b5F8Un86T6l"}}]}