{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOef4j3zoSpMgpYVZ5jzWF4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdu2cyZ2g3Rh","executionInfo":{"status":"ok","timestamp":1768374386766,"user_tz":-360,"elapsed":51,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}},"outputId":"3b76fdca-891b-4046-be3f-c563b94df95a"},"outputs":[{"output_type":"stream","name":"stdout","text":["﻿I HAD always thought Jack Gisburn rather a cheap genius-- though a good fellow enough--so it was no\n"]}],"source":["with open(\"/content/The_Verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n","  text = f.read()\n","\n","print(text[:100])"]},{"cell_type":"code","source":["import importlib\n","import tiktoken\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","IDs = tokenizer.encode(text)\n","print(IDs[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2SjoFQsYhkRH","executionInfo":{"status":"ok","timestamp":1768374393194,"user_tz":-360,"elapsed":5227,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}},"outputId":"858dfb0b-430d-4749-b42b-933b7567ff03"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[171, 119, 123, 40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257, 7026, 15632, 438, 996, 257, 922]\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","\n","block_size = 64\n","\n","def create_tf_dataset(ids, block_size):\n","    ids = tf.constant(ids, dtype=tf.int32)\n","    dataset = tf.data.Dataset.from_tensor_slices(ids)\n","    dataset = dataset.window(block_size + 1, shift=1, drop_remainder=True)\n","    dataset = dataset.flat_map(lambda x: x.batch(block_size + 1))\n","    dataset = dataset.map(lambda x: (x[:-1], x[1:]))\n","    return dataset\n","\n","dataset = create_tf_dataset(IDs, block_size)\n","\n","for x, y in dataset:\n","    print(\"Input:\", x.numpy(),\"\\n\", \"Target:\", y.numpy())\n","    break\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLrKzj5nh0j1","executionInfo":{"status":"ok","timestamp":1768374402241,"user_tz":-360,"elapsed":9046,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}},"outputId":"9b53723d-2507-456b-ad4d-5028e0446c33"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: [  171   119   123    40   367  2885  1464  1807  3619   402   271 10899\n","  2138   257  7026 15632   438   996   257   922  5891  1576   438   568\n","   340   373   645  1049  5975   284   502   284  3285   326    11   287\n","   262  6001   286   465 13476    11   339   550  5710   465 12036    11\n","  6405   257  5527 27075    11   290  4920  2241   287   257  4489    64\n","   319   262 34686 41976] \n"," Target: [  119   123    40   367  2885  1464  1807  3619   402   271 10899  2138\n","   257  7026 15632   438   996   257   922  5891  1576   438   568   340\n","   373   645  1049  5975   284   502   284  3285   326    11   287   262\n","  6001   286   465 13476    11   339   550  5710   465 12036    11  6405\n","   257  5527 27075    11   290  4920  2241   287   257  4489    64   319\n","   262 34686 41976    13]\n"]}]},{"cell_type":"code","source":["batch_size = 16\n","\n","batched_dataset = dataset.batch(batch_size, drop_remainder=True) #Drop last incomplete batch"],"metadata":{"id":"tew20QbviTTp","executionInfo":{"status":"ok","timestamp":1768374410260,"user_tz":-360,"elapsed":33,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["for input_ids, target_ids in batched_dataset.take(1): #take the first batch\n","    print(input_ids.shape, target_ids.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0K-Le900ibCl","executionInfo":{"status":"ok","timestamp":1768374411540,"user_tz":-360,"elapsed":43,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}},"outputId":"3ebbee41-8e7d-4c6a-a6dc-4a226d71e550"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["(16, 64) (16, 64)\n"]}]},{"cell_type":"code","source":["class GPTEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, vocab_size, max_len, d_model):\n","        super().__init__()\n","        self.token_emb = tf.keras.layers.Embedding(vocab_size, d_model) #Lookup table of size: vocab_size × d_model, each token id maps to a vector\n","\n","        self.pos_emb   = tf.keras.layers.Embedding(max_len, d_model) #lookup table of size: vocab_size x d_model, Each position index is maped to a vector\n","        #max_len = maximum sequence length the model can handle\n","        # It means: The largest number of tokens the model can process in one input sequence so max_len >= block_size, gpt2=1024, gpt3 = 2048\n","        #max_len = 128 then Position IDs: 0 to 127\n","        # when block size less than max len =max_len = 512, block size = 64 then Only positions 0–63 are used and others are ignored in forward pass\n","\n","\n","\n","    def call(self, input_ids):#forward pass\n","        B, T = tf.shape(input_ids)[0], tf.shape(input_ids)[1] #Extract batch size and sequence length\n","        positions = tf.range(0, T) #Create position indices like [0, 1, 2, ..., T-1]\n","        positions = tf.expand_dims(positions, 0)  # (1, T) Expand dims like (T,)->(1,T), prepare for batch broadcasting\n","        positions = tf.tile(positions, [B, 1])    # (B, T) Tile accross batch, resulting shape (B,T)\n","        ''' [\n","          [0, 1, 2, 3],\n","          [0, 1, 2, 3]\n","        ] '''\n","        x = self.token_emb(input_ids) #Token embedding lookup, input (B,T), output shape -> (B, T, d_model) Each token ID → vector.\n","        p = self.pos_emb(positions) #Positional embedding lookup, input(B,T), Output shape -> (B, T, d_model)\n","\n","        return x + p #(B, T, d_model) + (B, T, d_model)\n","\n","#Final output (B, T, d_model) means For each token in each sequence, you now have a vector.\n","# x[b, t] → vector of size d_model, x[0, 0] → embedding of 1st token of 1st sentence , x[1, 4] → embedding of 5th token of 2nd sentence\n","\n","\n","\n"],"metadata":{"id":"lKhFD5O0keCT","executionInfo":{"status":"ok","timestamp":1768374413262,"user_tz":-360,"elapsed":15,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["vocab_size = tokenizer.n_vocab\n","\n","embedding_layer = GPTEmbedding(\n","    vocab_size=vocab_size,\n","    max_len=block_size,\n","    d_model=256\n",")\n","\n","for input_ids, target_ids in batched_dataset:\n","    x = embedding_layer(input_ids)"],"metadata":{"id":"OJAOZQM_I5V9","executionInfo":{"status":"ok","timestamp":1768374418892,"user_tz":-360,"elapsed":2987,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["x[0,0] #vector of 1st token of 1st sequence"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"st-onsKSSIMc","executionInfo":{"status":"ok","timestamp":1768374420193,"user_tz":-360,"elapsed":16,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}},"outputId":"3e9aa3d8-b8f4-40e8-93cf-544788522bbe"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(256,), dtype=float32, numpy=\n","array([-1.28032565e-02, -1.21125691e-02,  2.53698602e-02,  4.59843501e-02,\n","       -2.76092142e-02, -2.54418589e-02, -3.05190720e-02,  7.02824742e-02,\n","       -1.04108229e-02, -3.79961729e-03, -7.57056102e-02,  5.65003380e-02,\n","        1.31392516e-02,  2.80474089e-02, -1.32741481e-02,  4.27048430e-02,\n","       -3.10556367e-02, -8.48719925e-02, -2.59093270e-02,  1.29586589e-02,\n","       -3.66173536e-02,  3.60317677e-02, -6.43103719e-02,  5.68809062e-02,\n","       -3.15227881e-02, -4.10348661e-02, -4.31039706e-02, -1.39475577e-02,\n","       -7.42787123e-02,  3.87852564e-02, -4.99856584e-02, -3.37286368e-02,\n","        1.33453589e-02, -2.87465677e-02,  5.08940108e-02, -8.77521634e-02,\n","        8.81641917e-03,  6.71612248e-02,  5.09570315e-02, -4.11628038e-02,\n","       -6.22373596e-02,  6.48895279e-02, -5.62416911e-02, -7.79256001e-02,\n","       -7.87595659e-03,  1.68758295e-02, -7.69135058e-02, -3.32330316e-02,\n","       -7.71699920e-02, -7.83336386e-02, -1.68330446e-02, -6.05981015e-02,\n","       -5.88530190e-02,  4.58967611e-02,  5.97976670e-02,  1.10011213e-02,\n","        1.13338362e-02,  1.33261420e-02,  2.85715051e-03, -5.64969704e-03,\n","        4.42670695e-02, -3.37857157e-02, -4.23981063e-02, -3.09814550e-02,\n","        7.36728013e-02, -8.76246765e-03,  3.67218517e-02, -3.11271902e-02,\n","        5.45017049e-02,  2.96345800e-02,  2.86744088e-02, -3.97810936e-02,\n","        2.95667611e-02, -6.77770376e-02,  2.29999404e-02, -3.24332714e-03,\n","        2.37218123e-02,  8.65924731e-03, -6.18660338e-02,  3.82093936e-02,\n","       -7.35469460e-02, -2.47812383e-02, -6.76393509e-03,  5.11197001e-02,\n","       -2.91885473e-02,  2.01320499e-02, -8.02170932e-02,  1.71432346e-02,\n","       -2.35276800e-02,  3.80279869e-02, -6.04034960e-03,  5.80149107e-02,\n","        4.08251174e-02,  8.96795616e-02, -2.03097984e-03,  1.30584463e-02,\n","        2.97283195e-03,  1.57265775e-02,  4.38200571e-02, -5.91735244e-02,\n","        2.46074237e-02, -5.76942563e-02, -6.62237406e-02, -1.09278932e-02,\n","       -2.49070972e-02, -2.25164928e-03,  4.04812545e-02,  2.09727287e-02,\n","        5.61317913e-02,  5.88351414e-02, -4.42895517e-02, -3.08756717e-02,\n","        4.06622253e-02,  7.86041394e-02,  2.06175074e-02,  6.62772879e-02,\n","        1.16247796e-02, -7.29333162e-02,  2.62165070e-03, -7.79442675e-03,\n","        2.30387896e-02,  1.52102485e-02,  3.96671407e-02,  4.91604134e-02,\n","       -5.84881380e-03, -1.02266539e-02, -7.99547881e-04,  3.12495977e-04,\n","        3.15465704e-02,  3.26236449e-02,  1.19352918e-02,  5.01100533e-02,\n","       -3.63198668e-02, -6.47472218e-04,  4.40869108e-02, -3.27497721e-02,\n","        1.87753327e-02,  1.41076744e-04,  7.17977062e-04,  6.13634586e-02,\n","       -3.10015567e-02, -9.90778208e-05,  5.95935360e-02,  1.38415135e-02,\n","        1.70829333e-02, -8.41160789e-02, -3.88242826e-02, -9.00997967e-02,\n","       -2.89798900e-03, -4.77557257e-03,  5.70741817e-02, -1.37144309e-02,\n","       -8.78987089e-03, -1.62054412e-02, -1.18595846e-02, -3.32936272e-02,\n","       -8.36065039e-03, -1.05409399e-02, -6.35093972e-02, -1.92905199e-02,\n","       -3.65429670e-02, -6.43668398e-02,  4.55291867e-02, -1.63666457e-02,\n","        2.83871442e-02,  2.76383869e-02, -1.55428685e-02,  4.42181267e-02,\n","        1.68107860e-02,  3.00205126e-03,  3.66729982e-02, -4.53961231e-02,\n","       -4.02250290e-02, -3.81431319e-02,  3.83671373e-03,  2.46582516e-02,\n","        4.38513421e-02, -1.25717409e-02,  3.26461159e-02,  5.90559244e-02,\n","        3.01442109e-02, -8.69088024e-02,  2.54590996e-02, -6.71013370e-02,\n","       -1.33768208e-02, -9.31729004e-03, -7.76445493e-03,  2.60032527e-03,\n","       -7.17424080e-02,  3.23817134e-02,  8.16823170e-03, -5.99940084e-02,\n","        6.34975880e-02, -2.17125639e-02, -9.12687629e-02, -1.12164617e-02,\n","       -1.89933181e-02, -3.60237844e-02,  7.31472597e-02, -2.92961672e-03,\n","        7.38886371e-02,  4.27771918e-02,  6.27666712e-02, -3.73905897e-03,\n","       -8.99885781e-03,  3.09386738e-02,  6.47935495e-02, -9.76681709e-04,\n","       -5.42863011e-02,  2.30120979e-02,  1.89153701e-02, -4.55707200e-02,\n","        2.07205825e-02,  1.90892071e-03,  8.30558687e-03, -8.38138610e-02,\n","        8.64179060e-03,  3.97036225e-03,  4.25641872e-02,  4.64277044e-02,\n","       -6.32661879e-02,  7.93668255e-03, -2.61437148e-04, -5.71186207e-02,\n","       -4.23486121e-02,  2.61880308e-02,  8.28831457e-03,  4.42904606e-02,\n","       -1.77821778e-02,  8.17274675e-03, -1.96213238e-02, -4.95494828e-02,\n","        5.75615540e-02, -6.27670735e-02, -1.00160576e-03, -2.07851157e-02,\n","        1.13513395e-02, -1.74909569e-02,  4.44965586e-02, -9.20232385e-03,\n","       -1.15697719e-02,  5.94989881e-02, -2.13986151e-02,  2.11175457e-02,\n","       -3.55761759e-02,  3.12312283e-02,  7.28490576e-02, -9.25267190e-02,\n","        5.20647615e-02,  1.50986202e-02, -4.18456458e-03, -2.83468980e-02,\n","       -9.71841812e-03,  2.44342722e-02,  9.13604721e-03, -2.70826332e-02],\n","      dtype=float32)>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["x[5,10] #  vector for 11th token of 6th sequence(0 base indexing)\n","\n","# Each row contains 64 vectors because each row in the a contains 64 IDs.\n","#Thats why x[5,64] will show out of index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgwuaQf2TDok","executionInfo":{"status":"ok","timestamp":1768378381441,"user_tz":-360,"elapsed":48,"user":{"displayName":"Pranab Roy","userId":"03404794500260995570"}},"outputId":"c82d8ced-3616-43e9-d43d-37a7bffba07b"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(256,), dtype=float32, numpy=\n","array([ 1.24114975e-02,  1.88071169e-02, -8.43556970e-03, -7.48472959e-02,\n","        2.42328513e-02, -4.46803719e-02,  1.80043206e-02, -4.18944508e-02,\n","        1.54528841e-02, -1.68267265e-02,  1.45807602e-02, -7.77342767e-02,\n","        8.11850652e-02, -7.71826133e-03,  7.91367739e-02, -5.75868860e-02,\n","        4.07451652e-02,  3.10507305e-02, -1.96940154e-02,  8.92629474e-03,\n","       -4.39274460e-02,  1.82956830e-03,  2.92868372e-02, -7.66075402e-02,\n","        5.37450612e-03,  6.52904660e-02, -4.50483896e-02, -7.82492012e-03,\n","       -2.03295909e-02, -1.48014426e-02,  6.52494058e-02,  7.79309273e-02,\n","       -8.85753408e-02, -8.69822502e-03, -4.14783582e-02, -6.09673187e-03,\n","        3.86983790e-02,  1.64917819e-02, -1.45010203e-02, -5.29844314e-04,\n","       -2.76053417e-02,  8.17303732e-03, -7.65282512e-02,  4.38488834e-03,\n","        6.76405206e-02,  8.90879780e-02, -5.66544421e-02,  4.81134653e-03,\n","        1.89237110e-02, -4.44311835e-02,  4.04871106e-02, -9.86433215e-03,\n","        5.02297990e-02,  7.06577674e-04, -3.15283053e-02, -7.04703704e-02,\n","       -2.39868909e-02,  2.61005796e-02,  5.68263978e-02,  3.29503380e-02,\n","       -2.86663659e-02,  3.66661437e-02,  5.31535819e-02,  1.58710703e-02,\n","        9.01680067e-03, -7.23752230e-02, -2.19206437e-02,  3.46874073e-02,\n","       -1.18948519e-05,  3.07577364e-02, -1.47311687e-02,  3.17785405e-02,\n","        3.87948006e-02,  1.31263640e-02, -1.18806250e-02,  5.30713312e-02,\n","        2.93136276e-02, -4.75790501e-02, -4.31097634e-02,  2.76745055e-02,\n","       -1.73295513e-02, -6.02718592e-02, -4.98392098e-02, -1.87221188e-02,\n","       -9.51432809e-03, -4.70951945e-02,  2.29346268e-02, -4.09460254e-03,\n","       -3.44593525e-02, -4.70596291e-02, -7.93735683e-02, -4.04376239e-02,\n","        6.72853515e-02, -1.70511715e-02,  5.11071905e-02,  1.64875165e-02,\n","        2.68227980e-02,  3.26855108e-03,  5.72296679e-02, -7.05890954e-02,\n","       -4.67595942e-02, -8.57408941e-02, -4.83744368e-02, -7.08685145e-02,\n","       -1.60264261e-02,  5.22027239e-02,  5.70520386e-03,  2.97266617e-02,\n","        4.64384109e-02, -4.72061709e-03,  2.20600367e-02,  5.30518368e-02,\n","        3.07436250e-02, -6.20584562e-03,  1.57794468e-02, -6.89504296e-03,\n","        6.53164461e-02,  9.54251364e-03,  8.35372582e-02,  1.94355994e-02,\n","       -1.93861239e-02, -5.63188680e-02,  7.42530003e-02,  3.83042209e-02,\n","        5.58414087e-02, -2.54986286e-02, -2.76282616e-02,  8.43895599e-03,\n","       -6.08277470e-02, -1.01857781e-02,  5.12240417e-02,  2.43186727e-02,\n","        1.11512169e-02,  1.66537911e-02, -2.03036778e-02,  1.69027969e-03,\n","        8.12950954e-02, -1.68540012e-02, -4.75407019e-03,  2.80403718e-03,\n","       -2.13209167e-02, -9.14676115e-03, -1.36390403e-02, -9.36530717e-03,\n","        1.92252547e-03, -2.56971233e-02, -1.95516925e-02, -5.81507757e-03,\n","       -7.27111027e-02,  1.11643337e-02,  1.56131275e-02,  4.63643707e-02,\n","       -5.10192290e-02, -3.67576256e-02,  6.20771199e-04,  2.07567848e-02,\n","       -2.03335620e-02,  4.71142903e-02, -5.84035404e-02,  6.84890971e-02,\n","        6.72757626e-04,  4.55046631e-02,  2.13048607e-03, -8.59869830e-03,\n","        5.04233353e-02,  4.07888070e-02,  1.08015668e-02, -1.03400350e-02,\n","        7.75955468e-02,  1.95543282e-02,  5.38125336e-02, -1.88988969e-02,\n","       -4.74858284e-03,  2.85992622e-02, -3.50115523e-02, -2.83320211e-02,\n","       -4.11361456e-03, -6.40338808e-02,  7.39135817e-02, -2.95374244e-02,\n","        4.08174396e-02,  3.15430760e-02,  3.90156433e-02,  6.55926578e-03,\n","        2.27468237e-02, -4.85412739e-02,  3.00862342e-02,  7.30263442e-03,\n","        2.28848085e-02, -1.68945082e-02,  8.50926042e-02,  2.23220848e-02,\n","        1.11778826e-03, -6.86775669e-02,  3.61108407e-03, -6.49646744e-02,\n","       -6.88197091e-03,  3.63207161e-02, -4.36872356e-02,  3.06274183e-02,\n","       -2.05277912e-02,  3.22969109e-02, -3.72213349e-02,  4.55495529e-03,\n","       -4.02068123e-02,  1.61696412e-02, -3.22689563e-02, -2.60341875e-02,\n","        5.88711128e-02,  3.42668295e-02,  3.46427076e-02, -9.67635028e-03,\n","       -3.90208401e-02,  7.45480508e-03, -4.09185067e-02,  9.33222845e-03,\n","       -2.27127559e-02, -5.28422743e-03, -1.22712981e-02,  4.97897491e-02,\n","        2.60527842e-02, -4.49479595e-02, -1.30453259e-02,  2.78117545e-02,\n","       -1.53468624e-02,  1.98487137e-02, -2.45898254e-02,  7.12950230e-02,\n","       -5.49446344e-02, -8.95054638e-03, -1.82829946e-02,  3.12573090e-03,\n","        3.40008996e-02, -4.19698469e-02,  2.32441183e-02,  4.58400510e-02,\n","        7.36826584e-02, -1.69415027e-02,  3.05244699e-02,  5.60789369e-03,\n","       -4.57800552e-03, -2.90224701e-03,  7.53481984e-02, -9.61853638e-02,\n","       -7.99967498e-02,  5.90976477e-02, -7.79404268e-02, -1.91164240e-02,\n","       -3.57631110e-02, -1.65887848e-02, -5.23248538e-02, -4.34105471e-03,\n","        6.57799542e-02, -1.38183720e-02,  7.62518272e-02,  1.30146556e-02],\n","      dtype=float32)>"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["#What is LookUp Table\n","A lookup table is just a matrix. Nothing more.\n","\n","For embeddings, embedding matrix = a 2D table of numbers = vocab_size x  d_model,\n","\n","Embedding(vocab_size, d_model)\n","\n","Each row = vector for one token ID\n","\n","\n","For positional encoding, Lookup table = max_len x d_model\n","\n","Each row = vector for one position.\n","\n","Embedding(max_len, d_model)\n","\n","# How lookup actually works (core idea)\n","Embedding lookup = row indexing\n","\n","No multiplication.\n","No dot product.\n","Just select rows.\n","\n","#Numeric  Example\n","vocab_size = 5, d_model = 3\n","\n","token embedding matrix:\\\n","token_emb_table = [\n","  \n","          [ 0.10,  0.20,  0.30 ],   # token 0\n","          [ 0.40,  0.50,  0.60 ],   # token 1\n","          [ 0.70,  0.80,  0.90 ],   # token 2\n","          [ 1.00,  1.10,  1.20 ],   # token 3\n","          [ 1.30,  1.40,  1.50 ]    # token 4\n","]\n","\n","input_ids = [2, 4, 1]\n","\n","Lookup Operations, token_emb(input_ids)\n","\n","Result = [\n","\n","        [0.70, 0.80, 0.90],   # row 2\n","        [1.30, 1.40, 1.50],   # row 4\n","        [0.40, 0.50, 0.60]    # row 1\n","]\n","\n","That’s it.\n","No computation — just indexing.\n","\n","Positional embedding lookup\n","\n","max_len = 6, d_model = 3\n","\n","positional embedding table,\n","pos_emb_table = [\n","\n","    [0.01, 0.02, 0.03],   # position 0\n","    [0.04, 0.05, 0.06],   # position 1\n","    [0.07, 0.08, 0.09],   # position 2\n","    [0.10, 0.11, 0.12],   # position 3\n","    [0.13, 0.14, 0.15],   # position 4\n","    [0.16, 0.17, 0.18]    # position 5\n","]\n","\n","positions = [0, 1, 2]\n","\n","Lookup, [\n","\n","    [0.01, 0.02, 0.03],   # pos 0\n","    [0.04, 0.05, 0.06],   # pos 1\n","    [0.07, 0.08, 0.09]    # pos 2\n","]\n","\n","#Combining token + position (final input)\n","token vectors = [\n","\n","     [0.70, 0.80, 0.90]\n","     [1.30, 1.40, 1.50]\n","     [0.40, 0.50, 0.60]\n","\n","]\n","\n","position vectors = [\n","\n","    [0.01, 0.02, 0.03]\n","    [0.04, 0.05, 0.06]\n","    [0.07, 0.08, 0.09]\n","\n","]\n","\n","Adding element wise: [\n","\n","    [0.71, 0.82, 0.93],\n","    [1.34, 1.45, 1.56],\n","    [0.47, 0.58, 0.69]\n","\n","]"],"metadata":{"id":"mZxjjUJHteni"}}]}